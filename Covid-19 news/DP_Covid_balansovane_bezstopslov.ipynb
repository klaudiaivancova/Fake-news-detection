{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detekcia falošných správ zameraných na tému Covid-19 - vybalansovaná trénovacia množina, vymazané stop slová"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# načítanie potrebných knižníc\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import WordPunctTokenizer, word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, concatenate, Activation, Dense, Dropout, Flatten, LSTM, Bidirectional, GRU, Conv1D, GlobalMaxPooling1D, MaxPooling1D, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#načítanie dátovej množiny\n",
    "korona=pd.read_csv(\"detekcia_Covid19.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vymazanie duplicitných hodnôt\n",
    "korona=korona.drop_duplicates(subset='url', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>perex</th>\n",
       "      <th>published</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>redaktor maria miz</td>\n",
       "      <td>https://www.hlavnespravy.sk/ceska-vlada-predlz...</td>\n",
       "      <td>Praha 9. apríla 2020 (SITA/HSP/Foto:SITA/AP-Ef...</td>\n",
       "      <td>&lt;p&gt;Praha 9. apríla 2020 (SITA/HSP/Foto:SITA/AP...</td>\n",
       "      <td>2020-04-09T17:40:29.000000+0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>ta3.com</td>\n",
       "      <td>https://www.ta3.com/clanok/1190300/pracuju-aj-...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Veterinári, ošetrovatelia zvierat aj zamestnan...</td>\n",
       "      <td>2020-08-17T10:37:25.000000+0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>hnonline.sk</td>\n",
       "      <td>https://finweb.hnonline.sk/financie-a-burzy/21...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Trhy sú naďalej znepokojené ekonomickými dôsle...</td>\n",
       "      <td>2020-03-11T19:37:00.000000+0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>ta3.com</td>\n",
       "      <td>https://www.ta3.com/clanok/1178311/taliansko-z...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>V Taliansku zatvoria v súvislosti s rýchlym ší...</td>\n",
       "      <td>2020-03-11T22:19:40.000000+0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Martina Max</td>\n",
       "      <td>https://www.hlavnespravy.sk/naozaj-koronavirus...</td>\n",
       "      <td>Bratislava 12. apríla 2020 (HSP/Foto:Pixabay)\\...</td>\n",
       "      <td>&lt;p&gt;Bratislava 12. apríla 2020 (HSP/Foto:Pixaba...</td>\n",
       "      <td>2020-04-12T12:31:47.000000+0200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   name                                                url  \\\n",
       "187  redaktor maria miz  https://www.hlavnespravy.sk/ceska-vlada-predlz...   \n",
       "189             ta3.com  https://www.ta3.com/clanok/1190300/pracuju-aj-...   \n",
       "190         hnonline.sk  https://finweb.hnonline.sk/financie-a-burzy/21...   \n",
       "191             ta3.com  https://www.ta3.com/clanok/1178311/taliansko-z...   \n",
       "194         Martina Max  https://www.hlavnespravy.sk/naozaj-koronavirus...   \n",
       "\n",
       "                                                  body  \\\n",
       "187  Praha 9. apríla 2020 (SITA/HSP/Foto:SITA/AP-Ef...   \n",
       "189                                                NaN   \n",
       "190                                                NaN   \n",
       "191                                                NaN   \n",
       "194  Bratislava 12. apríla 2020 (HSP/Foto:Pixabay)\\...   \n",
       "\n",
       "                                                 perex  \\\n",
       "187  <p>Praha 9. apríla 2020 (SITA/HSP/Foto:SITA/AP...   \n",
       "189  Veterinári, ošetrovatelia zvierat aj zamestnan...   \n",
       "190  Trhy sú naďalej znepokojené ekonomickými dôsle...   \n",
       "191  V Taliansku zatvoria v súvislosti s rýchlym ší...   \n",
       "194  <p>Bratislava 12. apríla 2020 (HSP/Foto:Pixaba...   \n",
       "\n",
       "                           published  \n",
       "187  2020-04-09T17:40:29.000000+0200  \n",
       "189  2020-08-17T10:37:25.000000+0200  \n",
       "190  2020-03-11T19:37:00.000000+0100  \n",
       "191  2020-03-11T22:19:40.000000+0100  \n",
       "194  2020-04-12T12:31:47.000000+0200  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ukážka dátovej množiny\n",
    "korona.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ta3.com                      1964\n",
       "redaktor janka papcunova     1691\n",
       "Martina Max                  1569\n",
       "redaktor maria dutkova       1539\n",
       "redaktor maria miz           1528\n",
       "aktuality.sk                 1522\n",
       "hnonline.sk                  1364\n",
       "tomas zajaros                1172\n",
       "sme.sk                        476\n",
       "zemavek.sk                    313\n",
       "hlavnespravy.sk               310\n",
       "redaktor jaroslav             234\n",
       "maria palastova               202\n",
       "slobodnyvysielac.sk           176\n",
       "Redakcia                       59\n",
       "redakcia                       29\n",
       "redaktor ivana                 21\n",
       "admin                          19\n",
       "redaktor ivana pl              10\n",
       "redaktor zuzana                10\n",
       "lenzena                         7\n",
       "redaktor renata karbanova       5\n",
       "bajecnezeny.sk                  2\n",
       "Martin Kočiš                    2\n",
       "::prop                          1\n",
       "Verrny                          1\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#výpis autorov a počet ich článkov\n",
    "korona.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vymazanie zdroja blog.sme pretože je nerelevantný\n",
    "korona=korona[korona.name != 'sme.sk']\n",
    "korona=korona[korona.name != 'redaktor renata karbanova']\n",
    "\n",
    "#nastavenie cieľového atribútu \n",
    "korona[\"label\"]=np.where(korona[\"name\"].str.contains(\"ta3\")|korona[\"name\"].str.contains(\"aktuality\")|korona[\"name\"].str.contains(\"hnonline\")|korona[\"name\"].str.contains(\"maria dutkova\")|korona[\"name\"].str.contains(\"janka papcunova\")\n",
    "                        |korona[\"name\"].str.contains(\"maria miz\")|korona[\"name\"].str.contains(\"Martina Max\")|korona[\"name\"].str.contains(\"tomas zajaros\")|korona[\"name\"].str.contains(\"hlavnespravy.sk\")\n",
    "                        |korona[\"name\"].str.contains(\"maria palastova\")|korona[\"name\"].str.contains(\"ivana\")|korona[\"name\"].str.contains(\"Martin Kočiš\"), 0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12894\n",
       "1      851\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pomer cieľového atribútu\n",
    "korona.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name            0\n",
       "url             0\n",
       "body         3401\n",
       "perex           8\n",
       "published       0\n",
       "label           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#počet prázdnych hodnôt\n",
    "korona.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veľa NA hodnôt mali pravdivé texty, čiže z perexu sme vzali text a priradili ho do body\n",
    "korona[\"body\"]=korona[\"body\"].fillna(korona[\"perex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name         0\n",
       "url          0\n",
       "body         5\n",
       "perex        8\n",
       "published    0\n",
       "label        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "korona.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vymazanie prázdnych hodnôt\n",
    "korona=korona.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#do množiny x vyberieme len atribúty name, body a label a do y len atribút label\n",
    "x=korona[['name','body','label']]\n",
    "y=korona[['label']]\n",
    "\n",
    "#rozdelenie množiny na trénovaciu a testovaciu v pomere 70:30\n",
    "SEED = 2000\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    8984\n",
       "1     631\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3902\n",
       "1     220\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#balansovanie trénovacej množiny - náhodné odstránenie určitého počtu (približne 50-60%) pravdivých správ, \n",
    "#kvôli vyrovnaniu pomeru cieľového atribútu\n",
    "to_remove_TA3 = np.random.choice(x_train[x_train['name']=='ta3.com'].index,size=1136,replace=False) \n",
    "x_train=x_train.drop(to_remove_TA3)\n",
    "\n",
    "to_remove_Max = np.random.choice(x_train[x_train['name']=='Martina Max'].index,size=1060,replace=False)\n",
    "x_train=x_train.drop(to_remove_Max)\n",
    "\n",
    "to_remove_miz = np.random.choice(x_train[x_train['name']=='redaktor maria miz'].index,size=998,replace=False)\n",
    "x_train=x_train.drop(to_remove_miz)\n",
    "\n",
    "to_remove_dutkova = np.random.choice(x_train[x_train['name']=='redaktor maria dutkova'].index,size=1045,replace=False)\n",
    "x_train=x_train.drop(to_remove_dutkova)\n",
    "\n",
    "to_remove_papcunova = np.random.choice(x_train[x_train['name']=='redaktor janka papcunova'].index,size=1137,replace=False)\n",
    "x_train=x_train.drop(to_remove_papcunova)\n",
    "\n",
    "to_remove_hsp = np.random.choice(x_train[x_train['name']=='maria palastova'].index,size=100,replace=False)\n",
    "x_train=x_train.drop(to_remove_hsp)\n",
    "\n",
    "to_remove_aktuality = np.random.choice(x_train[x_train['name']=='aktuality.sk'].index,size=990,replace=False)\n",
    "x_train=x_train.drop(to_remove_aktuality)\n",
    "\n",
    "to_remove_hnonline= np.random.choice(x_train[x_train['name']=='hnonline.sk'].index,size=870,replace=False)\n",
    "x_train=x_train.drop(to_remove_hnonline)\n",
    "\n",
    "to_remove_zajaros = np.random.choice(x_train[x_train['name']=='tomas zajaros'].index,size=821,replace=False)\n",
    "x_train=x_train.drop(to_remove_zajaros)\n",
    "\n",
    "to_remove_anton = np.random.choice(x_train[x_train['name']=='hlavnespravy.sk'].index,size=195,replace=False)\n",
    "x_train=x_train.drop(to_remove_anton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie nových hodnôt cieľového atribútu label do y_train\n",
    "y_train=x_train[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    632\n",
       "1    631\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    632\n",
       "1    631\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vymazanie atribútu name-názov autora článku, pretože detekciu sme vykonávali len zo samotného textu\n",
    "x_train=x_train.drop(columns=['name'])\n",
    "x_test=x_test.drop(columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie trénovacích a testovacích množín\n",
    "x_test.to_csv('x_test_clanky_korona.csv',encoding='utf-8')\n",
    "y_test.to_csv('y_test_label_korona.csv',encoding='utf-8')\n",
    "\n",
    "x_test=pd.read_csv('x_test_clanky_korona.csv',encoding='utf-8')\n",
    "y_test=pd.read_csv('y_test_label_korona.csv',encoding='utf-8')\n",
    "\n",
    "x_train.to_csv('x_train_clanky_korona_balans.csv',encoding='utf-8')\n",
    "y_train.to_csv('y_train_label_korona_balans.csv',encoding='utf-8')\n",
    "\n",
    "x_train=pd.read_csv('x_train_clanky_korona_balans.csv',encoding='utf-8')\n",
    "\n",
    "x_train=x_train.drop(columns=[\"Unnamed: 0\"])\n",
    "x_test=x_test.drop(columns=[\"Unnamed: 0\"])\n",
    "y_test=y_test.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definovanie, čo sa má z textu odstrániť\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+' #odstránenie @\n",
    "pat2 = r'https?://[^ ]+' #odstránenie odkazov https\n",
    "combined_pat = r'|'.join((pat1, pat2)) #kombinovane odstránenie pat1 aj pat2\n",
    "www_pat = r'www.[^ ]+' #odstránenie odkazov www\n",
    "pat3=r'http?://[^ ]+' #odstránenie odkazov http\n",
    "combined_pat2 = r'|'.join((www_pat, pat3)) \n",
    "\n",
    "pat4=r'img src=[^ ]+' #odstránenie odkazu na obrázok\n",
    "pat5=r'\\(SITA/[^)]*\\)' #odstránenie konkrétneho odkazu začínajúceho sa zdrojom SITA\n",
    "combined_pat3= r'|'.join((pat4, pat5)) \n",
    "pat6=r'\\(HSP/[^)]*\\)' #odstránenie konkrétneho odkazu začínajúceho sa zdrojom HSP\n",
    "pat7=r'\\(TASR/[^)]*\\)' #odstránenie konkrétneho odkazu začínajúceho sa zdrojom TASR\n",
    "combined_pat4= r'|'.join((pat6, pat7)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml') #dekódovanie html na všeobecný text\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.replace(\"ï¿½\", \"?\") #ošetrenie chyby keď nedekóduje dobre\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped3 = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped2= re.sub(combined_pat2, '', stripped3)\n",
    "    stripped1 = re.sub(combined_pat3, '', stripped2)\n",
    "    stripped = re.sub(combined_pat4, '', stripped1)\n",
    "    lower_case = stripped.lower()\n",
    "    letters_only = re.sub(\"[^a-zA-Z\\ÆÐƎƏƐƔĲŊŒẞÞǷȜæðǝəɛɣĳŋœĸſßþƿȝĄƁÇĐƊĘĦĮƘŁØƠŞȘŢȚŦŲƯY̨Ƴąɓçđɗęħįƙłøơşșţțŧųưy̨ƴÁÀÂÄǍĂĀÃÅǺĄÆǼǢƁĆĊĈČÇĎḌĐƊÐÉÈĖÊËĚĔĒĘẸƎƏƐĠĜǦĞĢƔáàâäǎăāãåǻąæǽǣɓćċĉčçďḍđɗðéèėêëěĕēęẹǝəɛġĝǧğģɣĤḤĦIÍÌİÎÏǏĬĪĨĮỊĲĴĶƘĹĻŁĽĿNŃN̈ŇÑŅŊÓÒÔÖǑŎŌÕŐỌØǾƠŒĥḥħıíìiîïǐĭīĩįịĳĵķƙĸĺļłľŀŉńn̈ňñņŋóòôöǒŏōõőọøǿơœŔŘŖŚŜŠŞȘṢẞŤŢṬŦÞÚÙÛÜǓŬŪŨŰŮŲỤƯẂẀŴẄǷÝỲŶŸȲỸƳŹŻŽẒŕřŗſśŝšşșṣßťţṭŧþúùûüǔŭūũűůųụưẃẁŵẅƿýỳŷÿȳỹƴźżžẓ]\", \" \", lower_case)\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definovanie slovenských stop slov\n",
    "stop_words = frozenset([\"tasr\",\"a\",\"aby\",\"aj\",\"ak\",\"ako\",\"ale\",\"alebo\",\"and\",\"ani\",\"áno\",\"asi\",\"až\",\"bez\",\"bude\",\"budem\",\"budeš\",\"budeme\",\"budete\",\"budú\",\"by\",\"bol\",\"bola\",\"boli\",\"bolo\",\"byť\",\"cez\",\"čo\",\"či\",\"ďalší\",\"ďalšia\",\"ďalšie\",\"dnes\",\"do\",\"ho\",\"ešte\",\"for\",\"i\",\"ja\",\"je\",\"jeho\",\"jej\",\"ich\",\"iba\",\"iné\",\"iný\",\"som\",\"si\",\"sme\",\"sú\",\"k\",\"kam\",\"každý\",\"každá\",\"každé\",\"každí\",\"kde\",\"keď\",\"kto\",\"ktorá\",\"ktoré\",\"ktorou\",\"ktorý\",\"ktorí\",\"ku\",\"lebo\",\"len\",\"ma\",\"mať\",\"má\",\"máte\",\"medzi\",\"mi\",\"mna\",\"mne\",\"mnou\",\"musieť\",\"môcť\",\"môj\",\"môže\",\"my\",\"na\",\"nad\",\"nám\",\"náš\",\"naši\",\"nie\",\"nech\",\"než\",\"nič\",\"niektorý\",\"nové\",\"nový\",\"nová\",\"noví\",\"o\",\"od\",\"odo\",\"of\",\"on\",\"ona\",\"ono\",\"oni\",\"ony\",\"po\",\"pod\",\"podľa\",\"pokiaľ\",\"potom\",\"práve\",\"pre\",\"prečo\",\"preto\",\"pretože\",\"prvý\",\"prvá\",\"prvé\",\"prví\",\"pred\",\"predo\",\"pri\",\"pýta\",\"s\",\"sa\",\"so\",\"svoje\",\"svoj\",\"svojich\",\"svojím\",\"svojími\",\"ta\",\"tak\",\"takže\",\"táto\",\"teda\",\"te\",\"tě\",\"ten\",\"tento\",\"the\",\"tieto\",\"tým\",\"týmto\",\"tiež\",\"to\",\"toto\",\"toho\",\"tohoto\",\"tom\",\"tomto\",\"tomuto\",\"tu\",\"tú\",\"túto\",\"tvoj\",\"ty\",\"tvojími\",\"už\",\"v\",\"vám\",\"váš\",\"vaše\",\"vo\",\"viac\",\"však\",\"všetok\",\"vy\",\"z\",\"za\",\"zo\",\"že\",\"buď\",\"ju\",\"menej\",\"moja\",\"moje\",\"späť\",\"ste\",\"tá\",\"tam\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#čistenie textu na trénovacej a testovacej množine\n",
    "testing_train = x_train.body[0:(len(x_train))]\n",
    "test_result_train = []\n",
    "for t in testing_train:\n",
    "    test_result_train.append(cleaner(t))\n",
    "\n",
    "\n",
    "testing_test = x_test.body[0:(len(x_test))]\n",
    "test_result_test = []\n",
    "for t in testing_test:\n",
    "    test_result_test.append(cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vytvorenie dataframe clean_df\n",
    "clean_train = pd.DataFrame(test_result_train,columns=['body'])\n",
    "clean_train['label'] = x_train.label #pridanie stĺpca label\n",
    "\n",
    "clean_test = pd.DataFrame(test_result_test,columns=['body'])\n",
    "clean_test['label'] = x_test.label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie vyčisteného textu\n",
    "clean_train.to_csv('clean_train_korona_balans.csv',encoding='utf-8')\n",
    "csv_train = 'clean_train_korona_balans.csv'\n",
    "df_train = pd.read_csv(csv_train,index_col=0)\n",
    "\n",
    "clean_test.to_csv('clean_test_korona.csv',encoding='utf-8')\n",
    "csv_test = 'clean_test_korona.csv'\n",
    "df_test = pd.read_csv(csv_test,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True) #vymazanie prázdnych hodnôt\n",
    "df_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_test.dropna(inplace=True) #vymazanie prázdnych hodnôt\n",
    "df_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>zatiaľ čo európu paralyzuje koronavírus stále ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>peking februára čína redukuje clá na dovoz usa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lausanne marca prezident európskej atletickej ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>brusel mája európska únia vyjadrila podporu sv...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bratislava apríla redaktorka denníka sme býval...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label\n",
       "0  zatiaľ čo európu paralyzuje koronavírus stále ...      0\n",
       "1  peking februára čína redukuje clá na dovoz usa...      0\n",
       "2  lausanne marca prezident európskej atletickej ...      0\n",
       "3  brusel mája európska únia vyjadrila podporu sv...      0\n",
       "4  bratislava apríla redaktorka denníka sme býval...      1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ukážka vyčistenej dátovej množiny\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    632\n",
       "1    631\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3901\n",
       "1     220\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vytvorenie tokenov zo slov pre trénovaciu a testovaciu množinu\n",
    "df_token_train = df_train['body'].values.tolist()\n",
    "\n",
    "token_train=list()\n",
    "for i in df_token_train:\n",
    "    word_train=nltk.word_tokenize(i)\n",
    "    word_train = [w for w in word_train if not w in stop_words]\n",
    "    token_train.append(word_train)\n",
    "\n",
    "\n",
    "df_token_test = df_test['body'].values.tolist()\n",
    "\n",
    "token_test=list()\n",
    "for i in df_token_test:\n",
    "    word_test=nltk.word_tokenize(i)\n",
    "    word_test = [w for w in word_test if not w in stop_words]\n",
    "    token_test.append(word_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "##word embeddings pomocou Word2Vec\n",
    "model = Word2Vec(token_train, min_count = 1)\n",
    "vocabulary = model.wv.vocab\n",
    "\n",
    "name = 'w2v.txt'\n",
    "model.wv.save_word2vec_format(name, binary = False)\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('','w2v.txt'), encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word_train = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word_train] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najdenych 49667 jedinecnych tokenov.\n"
     ]
    }
   ],
   "source": [
    "max_length = 3700\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(token_train)\n",
    "\n",
    "seq_train = tokenizer.texts_to_sequences(token_train)\n",
    "seq_test = tokenizer.texts_to_sequences(token_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Najdenych %s jedinecnych tokenov.' %len (word_index))\n",
    "\n",
    "train_padding = pad_sequences(seq_train, max_length)\n",
    "test_padding = pad_sequences(seq_test, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49668\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word_train, ii in word_index.items():\n",
    "    if ii > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word_train)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[ii] = embedding_vector\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['label'].values\n",
    "y_test = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 3700)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 3700, 100)         4966800   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 3699, 100)         20100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 5,013,013\n",
      "Trainable params: 5,013,013\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#architektúra CNN modelu\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model_cnn = Model(inputs=inputs, outputs=output)\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie modelu\n",
    "saved_model = \"model_cnn_korona_balansbezstop.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trénovanie modelu\n",
    "history = model_cnn.fit(train_padding, y_train, epochs=5, batch_size=32, validation_split=0.1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#načítanie modelu\n",
    "model_cnn=load_model('model_cnn_korona_balansbezstop.hdf5')\n",
    "\n",
    "#predikcia na testovacích dátach pomocou natrénovaného modelu,\n",
    "#vypísanie kontingenčnej tabuľky a metrík na vyhodnotenie ako úspešnosť, návrtanosť, F1 ...\n",
    "y_cnn = model_cnn.predict(test_padding)\n",
    "print('Roc auc score is {}'.format(roc_auc_score(y_test, y_cnn)))\n",
    "y_int = np.zeros_like(y_cnn)\n",
    "y_int[y_cnn > 0.5] = 1\n",
    "print('Accuracy is {}'.format(accuracy_score(y_test,y_int)))\n",
    "\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              | Precision | Recall | F1-score | Support |\n",
    "|:------------:|:---------:|:------:|:--------:|:-------:|\n",
    "|       0      |    0.98   |  0.82  |   0.89   |   3901  |\n",
    "|       1      |    0.19   |  0.76  |   0.30   |   220   |\n",
    "|              |           |        |          |         |\n",
    "|   Accuracy   |           |        |   0.81   |   4121  |\n",
    "|   Macro avg  |    0.59   |  0.79  |   0.60   |   4121  |\n",
    "| Weighted avg |    0.94   |  0.81  |   0.86   |   4121  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy : 0.813637\n",
    "\n",
    "ROC : 0.863783"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Actual/Predicted | Fake news | True news |\n",
    "|------------------|-----------|-----------|\n",
    "| Fake news        |   TP-167  |   FN-53   |\n",
    "| True news        |   FP-715  |  TN-3186  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 3700)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 3700, 100)         4966800   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 5,100,689\n",
      "Trainable params: 5,100,689\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#architektúra LSTM modelu\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model_lstm = Model(inputs=inputs, outputs=output)\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie modelu\n",
    "saved_model = \"model_lstm_korona_balansbezstop.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trénovanie modelu\n",
    "history = model_lstm.fit(train_padding, y_train, epochs=5, batch_size=32, validation_split=0.1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#načítanie modelu\n",
    "model_lstm=load_model('model_lstm_korona_balansbezstop.hdf5')\n",
    "\n",
    "#predikcia na testovacích dátach pomocou natrénovaného modelu,\n",
    "#vypísanie kontingenčnej tabuľky a metrík na vyhodnotenie ako úspešnosť, návrtanosť, F1 ...\n",
    "y_cnn = model_lstm.predict(test_padding)\n",
    "print('Roc auc score is {}'.format(roc_auc_score(y_test, y_cnn)))\n",
    "y_int = np.zeros_like(y_cnn)\n",
    "y_int[y_cnn > 0.5] = 1\n",
    "print('Accuracy is {}'.format(accuracy_score(y_test,y_int)))\n",
    "\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              | Precision | Recall | F1-score | Support |\n",
    "|:------------:|:---------:|:------:|:--------:|:-------:|\n",
    "|       0      |    0.99   |  0.82  |   0.90   |   3901  |\n",
    "|       1      |    0.22   |  0.89  |   0.35   |   220   |\n",
    "|              |           |        |          |         |\n",
    "|   Accuracy   |           |        |   0.83   |   4121  |\n",
    "|   Macro avg  |    0.61   |  0.85  |   0.63   |   4121  |\n",
    "| Weighted avg |    0.95   |  0.83  |   0.87   |   4121  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy : 0.826256\n",
    "\n",
    "ROC : 0.930680"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Actual/Predicted | Fake news | True news |\n",
    "|------------------|-----------|-----------|\n",
    "| Fake news        |   TP-195  |   FN-25   |\n",
    "| True news        |   FP-691  |  TN-3210  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 3700)              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 3700, 100)         4966800   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 3700, 100)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 3700, 128)         84480     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 3698, 32)          12320     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,065,777\n",
      "Trainable params: 5,065,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#architektúra Bi-LSTM + CNN modelu\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "x = Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model_bilstm = Model(inputs=inputs, outputs=output)\n",
    "model_bilstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model_bilstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie modelu\n",
    "saved_model = \"model_bilstm_korona_balansbezstop.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trénovanie modelu\n",
    "history = model_bilstm.fit(train_padding, y_train, epochs=5, batch_size=32, validation_split=0.1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#načítanie modelu\n",
    "model_bilstm=load_model('model_bilstm_korona_balansbezstop.hdf5')\n",
    "\n",
    "#predikcia na testovacích dátach pomocou natrénovaného modelu,\n",
    "#vypísanie kontingenčnej tabuľky a metrík na vyhodnotenie ako úspešnosť, návrtanosť, F1 ...\n",
    "y_cnn = model_bilstm.predict(test_padding)\n",
    "print('Roc auc score is {}'.format(roc_auc_score(y_test, y_cnn)))\n",
    "y_int = np.zeros_like(y_cnn)\n",
    "y_int[y_cnn > 0.5] = 1\n",
    "print('Accuracy is {}'.format(accuracy_score(y_test,y_int)))\n",
    "\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              | Precision | Recall | F1-score | Support |\n",
    "|:------------:|:---------:|:------:|:--------:|:-------:|\n",
    "|       0      |    0.99   |  0.97  |   0.98   |   3901  |\n",
    "|       1      |    0.63   |  0.79  |   0.70   |   220   |\n",
    "|              |           |        |          |         |\n",
    "|   Accuracy   |           |        |   0.96   |   4121  |\n",
    "|   Macro avg  |    0.81   |  0.88  |   0.84   |   4121  |\n",
    "| Weighted avg |    0.97   |  0.96  |   0.97   |   4121  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy : 0.963601\n",
    "\n",
    "ROC : 0.936874"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Actual/Predicted | Fake news | True news |\n",
    "|------------------|-----------|-----------|\n",
    "| Fake news        |   TP-173  |   FN-47   |\n",
    "| True news        |   FP-103  |  TN-3798  |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
