{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detekcia falošných politických a ekonomických správ - ponechanie rozdelenia cieľového atribútu, ponechané stop slová"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# načítanie potrebných knižníc\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import WordPunctTokenizer, word_tokenize\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import os\n",
    "from tensorflow.python.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import Sequential, Model, load_model\n",
    "from keras.layers import Input, concatenate, Activation, Dense, Dropout, Flatten, LSTM, Bidirectional, GRU, Conv1D, GlobalMaxPooling1D, MaxPooling1D, SpatialDropout1D, GlobalAveragePooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score,roc_auc_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#načítanie dátových množín\n",
    "home=pd.read_csv(\"detekcia_Homenews2.csv\")\n",
    "home2=pd.read_csv(\"detekcia_Homenews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spojenie dvoch dátových množín a vymazanie potenciálnych duplikátov podľa url adresy článku\n",
    "home_nove=home2.append(home, ignore_index=True, sort=False)\n",
    "home_nove=home_nove.drop_duplicates(subset='url', keep=\"last\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>url</th>\n",
       "      <th>body</th>\n",
       "      <th>perex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>magnificat.sk</td>\n",
       "      <td>http://www.magnificat.sk/cudna-ekumena-na-fest...</td>\n",
       "      <td>\\r\\n \\r\\n„Katolícka moderna“, ako sa zdá, zav...</td>\n",
       "      <td>&lt;p&gt;&amp;nbsp; &amp;nbsp; &amp;#8222;Katolícka moderna&amp;#822...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>magnificat.sk</td>\n",
       "      <td>http://www.magnificat.sk/nevsedna-vystava-v-br...</td>\n",
       "      <td>\\r\\nMilí priatelia, Robert Richter prešiel vo ...</td>\n",
       "      <td>&lt;p&gt;Milí priatelia, Robert Richter prešiel vo s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>magnificat.sk</td>\n",
       "      <td>http://www.magnificat.sk/ukrajinske-peklo/</td>\n",
       "      <td>Média vylíčila Berkut a další činitele jako fa...</td>\n",
       "      <td>&lt;p&gt;Média vylíčila Berkut a další činitele jako...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Petit Press</td>\n",
       "      <td>https://zriedkavechoroby.blog.sme.sk/c/522415/...</td>\n",
       "      <td>Rakovina pankreasu má najnižšiu mieru prežitia...</td>\n",
       "      <td>Rakovina pankreasu má najnižšiu mieru prežitia...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>ta3.com</td>\n",
       "      <td>https://www.ta3.com/clanok/1170735/vnima-reali...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Stratifikácia nemocníc zostáva kompletne pripr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             name                                                url  \\\n",
       "1   magnificat.sk  http://www.magnificat.sk/cudna-ekumena-na-fest...   \n",
       "2   magnificat.sk  http://www.magnificat.sk/nevsedna-vystava-v-br...   \n",
       "3   magnificat.sk         http://www.magnificat.sk/ukrajinske-peklo/   \n",
       "20    Petit Press  https://zriedkavechoroby.blog.sme.sk/c/522415/...   \n",
       "21        ta3.com  https://www.ta3.com/clanok/1170735/vnima-reali...   \n",
       "\n",
       "                                                 body  \\\n",
       "1    \\r\\n \\r\\n„Katolícka moderna“, ako sa zdá, zav...   \n",
       "2   \\r\\nMilí priatelia, Robert Richter prešiel vo ...   \n",
       "3   Média vylíčila Berkut a další činitele jako fa...   \n",
       "20  Rakovina pankreasu má najnižšiu mieru prežitia...   \n",
       "21                                                NaN   \n",
       "\n",
       "                                                perex  \n",
       "1   <p>&nbsp; &nbsp; &#8222;Katolícka moderna&#822...  \n",
       "2   <p>Milí priatelia, Robert Richter prešiel vo s...  \n",
       "3   <p>Média vylíčila Berkut a další činitele jako...  \n",
       "20  Rakovina pankreasu má najnižšiu mieru prežitia...  \n",
       "21  Stratifikácia nemocníc zostáva kompletne pripr...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ukážka dátovej množiny\n",
    "home_nove.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TASR                         10368\n",
       "slobodnyvysielac.sk           7070\n",
       "Martina Max                   2356\n",
       "redaktor maria miz            1824\n",
       "sme.sk                        1424\n",
       "ta3.com                       1155\n",
       "redaktor maria dutkova        1140\n",
       "aktuality.sk                  1066\n",
       "redaktor jana frielichova     1058\n",
       "redaktor janka papcunova       973\n",
       "TASR - HSP                     813\n",
       "hnonline.sk                    708\n",
       "maria palastova                338\n",
       "redaktor jaroslav              332\n",
       "Redakcia                       310\n",
       "zemavek.sk                     297\n",
       "redaktor zuzana                279\n",
       "redakto anton                  180\n",
       "tomas zajaros                  158\n",
       "redaktor lukas                 144\n",
       "::prop                          82\n",
       "Autor                           74\n",
       "Petit Press                     69\n",
       "admin                           61\n",
       "redaktor ivana                  52\n",
       "redaktor viliam varga           49\n",
       "magnificat.sk                   44\n",
       "HSP                             18\n",
       "redaktor slavka                 15\n",
       "TASR-OTS                        15\n",
       "oliolijanko                      8\n",
       "Andrij Stryj                     5\n",
       "redaktor maros kyjovsky          4\n",
       "Roland Edvardsen                 3\n",
       "hlavnespravy.sk                  2\n",
       "Artur                            1\n",
       "Name: name, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#výpis autorov a počet ich článkov\n",
    "home_nove.name.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vymazanie zdroja blog.sme pretože je nerelevantny\n",
    "home_nove=home_nove[home_nove.name != 'sme.sk']\n",
    "home_nove=home_nove[home_nove.name != 'Petit Press'] \n",
    "\n",
    "#nastavenie cieľového atribútu \n",
    "home_nove[\"label\"]=np.where(home_nove[\"name\"].str.contains(\"ta3\")|home_nove[\"name\"].str.contains(\"aktuality\")|home_nove[\"name\"].str.contains(\"TASR\")|home_nove[\"name\"].str.contains(\"hnonline\")|home_nove[\"name\"].str.contains(\"Autor\")|home_nove[\"name\"].str.contains(\"maria dutkova\")|home_nove[\"name\"].str.contains(\"janka papcunova\")\n",
    "                        |home_nove[\"name\"].str.contains(\"maria miz\")|home_nove[\"name\"].str.contains(\"Martina Max\")|home_nove[\"name\"].str.contains(\"tomas zajaros\")|home_nove[\"name\"].str.contains(\"jana frielichova\")|home_nove[\"name\"].str.contains(\"anton\")|home_nove[\"name\"].str.contains(\"maros kyjovsky\"), 0,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    21892\n",
       "1     9110\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pomer cieľového atribútu\n",
    "home_nove.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name        0\n",
       "url         0\n",
       "body     2307\n",
       "perex      95\n",
       "label       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#počet prázdnych hodnôt\n",
    "home_nove.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#veľa NA hodnôt mali pravdivé texty, čiže z perexu sme vzali text a priradili ho do body\n",
    "home_nove[\"body\"]=home_nove[\"body\"].fillna(home_nove[\"perex\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "name      0\n",
       "url       0\n",
       "body     29\n",
       "perex    95\n",
       "label     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "home_nove.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vymazanie prázdnych hodnôt\n",
    "home_nove=home_nove.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=home_nove[['name','body','label']]\n",
    "y=home_nove[['label']]\n",
    "\n",
    "#rozdelenie množiny na trénovaciu a testovaciu v pomere 70:30\n",
    "SEED = 2000\n",
    "x_train,x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15363\n",
       "1     6271\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6496\n",
       "1    2777\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vymazanie atribútu name-názov autora článku, pretože detekciu sme vykonávali len zo samotného textu\n",
    "x_train=x_train.drop(columns=['name'])\n",
    "x_test=x_test.drop(columns=['name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie trénovacích a testovacích množín\n",
    "x_test.to_csv('x_test_clanky_home.csv',encoding='utf-8')\n",
    "y_test.to_csv('y_test_label_home.csv',encoding='utf-8')\n",
    "\n",
    "x_test=pd.read_csv('x_test_clanky_home.csv',encoding='utf-8')\n",
    "y_test=pd.read_csv('y_test_label_home.csv',encoding='utf-8')\n",
    "\n",
    "x_train.to_csv('x_train_clanky_home_nebalanssostop.csv',encoding='utf-8')\n",
    "y_train.to_csv('y_train_label_home_nebalanssostop.csv',encoding='utf-8')\n",
    "\n",
    "x_train=pd.read_csv('x_train_clanky_home_nebalanssostop.csv',encoding='utf-8')\n",
    "\n",
    "x_train=x_train.drop(columns=[\"Unnamed: 0\"])\n",
    "x_test=x_test.drop(columns=[\"Unnamed: 0\"])\n",
    "y_test=y_test.drop(columns=[\"Unnamed: 0\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definovanie, čo sa má z textu odstrániť\n",
    "tok = WordPunctTokenizer()\n",
    "\n",
    "pat1 = r'@[A-Za-z0-9_]+' #odstránenie @\n",
    "pat2 = r'https?://[^ ]+' #odstránenie odkazov https\n",
    "combined_pat = r'|'.join((pat1, pat2)) #kombinovane odstránenie pat1 aj pat2\n",
    "www_pat = r'www.[^ ]+' #odstránenie odkazov www\n",
    "pat3=r'http?://[^ ]+' #odstránenie odkazov http\n",
    "combined_pat2 = r'|'.join((www_pat, pat3)) \n",
    "\n",
    "pat4=r'img src=[^ ]+' #odstránenie odkazu na obrázok\n",
    "pat5=r'\\(SITA/[^)]*\\)' #odstránenie konkrétneho odkazu začínajúceho sa zdrojom SITA\n",
    "combined_pat3= r'|'.join((pat4, pat5)) \n",
    "pat6=r'\\(HSP/[^)]*\\)' #odstránenie konkrétneho odkazu začínajúceho sa zdrojom HSP\n",
    "pat7=r'\\(TASR/[^)]*\\)' #odstránenie konkrétneho odkazu začínajúceho sa zdrojom TASR\n",
    "combined_pat4= r'|'.join((pat6, pat7)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(text):\n",
    "    soup = BeautifulSoup(text, 'lxml') #dekódovanie html na všeobecný text\n",
    "    souped = soup.get_text()\n",
    "    try:\n",
    "        bom_removed = souped.replace(\"ï¿½\", \"?\") #ošetrenie chyby keď nedekóduje dobre\n",
    "    except:\n",
    "        bom_removed = souped\n",
    "    stripped3 = re.sub(combined_pat, '', bom_removed)\n",
    "    stripped2= re.sub(combined_pat2, '', stripped3)\n",
    "    stripped1 = re.sub(combined_pat3, '', stripped2)\n",
    "    stripped = re.sub(combined_pat4, '', stripped1)\n",
    "    lower_case = stripped.lower()\n",
    "    letters_only = re.sub(\"[^a-zA-Z\\ÆÐƎƏƐƔĲŊŒẞÞǷȜæðǝəɛɣĳŋœĸſßþƿȝĄƁÇĐƊĘĦĮƘŁØƠŞȘŢȚŦŲƯY̨Ƴąɓçđɗęħįƙłøơşșţțŧųưy̨ƴÁÀÂÄǍĂĀÃÅǺĄÆǼǢƁĆĊĈČÇĎḌĐƊÐÉÈĖÊËĚĔĒĘẸƎƏƐĠĜǦĞĢƔáàâäǎăāãåǻąæǽǣɓćċĉčçďḍđɗðéèėêëěĕēęẹǝəɛġĝǧğģɣĤḤĦIÍÌİÎÏǏĬĪĨĮỊĲĴĶƘĹĻŁĽĿNŃN̈ŇÑŅŊÓÒÔÖǑŎŌÕŐỌØǾƠŒĥḥħıíìiîïǐĭīĩįịĳĵķƙĸĺļłľŀŉńn̈ňñņŋóòôöǒŏōõőọøǿơœŔŘŖŚŜŠŞȘṢẞŤŢṬŦÞÚÙÛÜǓŬŪŨŰŮŲỤƯẂẀŴẄǷÝỲŶŸȲỸƳŹŻŽẒŕřŗſśŝšşșṣßťţṭŧþúùûüǔŭūũűůųụưẃẁŵẅƿýỳŷÿȳỹƴźżžẓ]\", \" \", lower_case)\n",
    "    words = [x for x  in tok.tokenize(letters_only) if len(x) > 1]\n",
    "    return (\" \".join(words)).strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Klaudia\\Anaconda3\\envs\\tensorflow_env2\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"http://dolezite.sk/Bola_nezna_revolucia_november_1989_podvodom.html\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n",
      "C:\\Users\\Klaudia\\Anaconda3\\envs\\tensorflow_env2\\lib\\site-packages\\bs4\\__init__.py:421: MarkupResemblesLocatorWarning: \"http://www.bnaibritheurope.org/bbe/content/view/640/lang,en/\n",
      "\" looks like a URL. Beautiful Soup is not an HTTP client. You should probably use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n",
      "  MarkupResemblesLocatorWarning\n"
     ]
    }
   ],
   "source": [
    "#čistenie textu na trénovacej a testovacej množine\n",
    "testing_train = x_train.body[0:(len(x_train))]\n",
    "test_result_train = []\n",
    "for t in testing_train:\n",
    "    test_result_train.append(cleaner(t))\n",
    "\n",
    "\n",
    "testing_test = x_test.body[0:(len(x_test))]\n",
    "test_result_test = []\n",
    "for t in testing_test:\n",
    "    test_result_test.append(cleaner(t))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vytvorenie dataframe clean_df\n",
    "clean_train = pd.DataFrame(test_result_train,columns=['body'])\n",
    "clean_train['label'] = x_train.label #pridanie stĺpca label\n",
    "\n",
    "clean_test = pd.DataFrame(test_result_test,columns=['body'])\n",
    "clean_test['label'] = x_test.label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie vyčisteného textu\n",
    "clean_train.to_csv('clean_train_home_nebalanssostop.csv',encoding='utf-8')\n",
    "csv_train = 'clean_train_home_nebalanssostop.csv'\n",
    "df_train = pd.read_csv(csv_train,index_col=0)\n",
    "\n",
    "clean_test.to_csv('clean_test_home.csv',encoding='utf-8')\n",
    "csv_test = 'clean_test_home.csv'\n",
    "df_test = pd.read_csv(csv_test,index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.dropna(inplace=True) #vymazanie prázdnych hodnôt\n",
    "df_train.reset_index(drop=True,inplace=True)\n",
    "\n",
    "df_test.dropna(inplace=True) #vymazanie prázdnych hodnôt\n",
    "df_test.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hrachovo decembra všetky žiadosti posúdila cer...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>source kočnera obvinili objednávky vraždy kuci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>prezident peru martín vizcarra jeho kolumbijsk...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nitra novembra tasr na univerzite konštantína ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>melbourne januára aktualizované slovenská juni...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                body  label\n",
       "0  hrachovo decembra všetky žiadosti posúdila cer...      0\n",
       "1  source kočnera obvinili objednávky vraždy kuci...      1\n",
       "2  prezident peru martín vizcarra jeho kolumbijsk...      1\n",
       "3  nitra novembra tasr na univerzite konštantína ...      0\n",
       "4  melbourne januára aktualizované slovenská juni...      1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ukážka vyčistenej dátovej množiny\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    15362\n",
       "1     6263\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6495\n",
       "1    2776\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vytvorenie tokenov zo slov pre trénovaciu a testovaciu množinu\n",
    "df_token_train = df_train['body'].values.tolist()\n",
    "\n",
    "token_train=list()\n",
    "for i in df_token_train:\n",
    "    word_train=nltk.word_tokenize(i)\n",
    "    token_train.append(word_train)\n",
    "\n",
    "\n",
    "df_token_test = df_test['body'].values.tolist()\n",
    "\n",
    "token_test=list()\n",
    "for i in df_token_test:\n",
    "    word_test=nltk.word_tokenize(i)\n",
    "    token_test.append(word_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "##word embeddings pomocou Word2Vec\n",
    "model = Word2Vec(token_train, min_count = 1)\n",
    "vocabulary = model.wv.vocab\n",
    "\n",
    "name = 'w2v.txt'\n",
    "model.wv.save_word2vec_format(name, binary = False)\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('','w2v.txt'), encoding = \"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word_train = values[0]\n",
    "    coefs = np.asarray(values[1:])\n",
    "    embeddings_index[word_train] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Najdenych 201941 jedinecnych tokenov.\n"
     ]
    }
   ],
   "source": [
    "max_length = 1000\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(token_train)\n",
    "\n",
    "seq_train = tokenizer.texts_to_sequences(token_train)\n",
    "seq_test = tokenizer.texts_to_sequences(token_test)\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "print('Najdenych %s jedinecnych tokenov.' %len (word_index))\n",
    "\n",
    "train_padding = pad_sequences(seq_train, max_length)\n",
    "test_padding = pad_sequences(seq_test, max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "201942\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word_train, ii in word_index.items():\n",
    "    if ii > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word_train)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[ii] = embedding_vector\n",
    "print(num_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = df_train['label'].values\n",
    "y_test = df_test['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 1000, 100)         20194200  \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 999, 100)          20100     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_1 (Glob (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               25856     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 20,240,413\n",
      "Trainable params: 20,240,413\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#architektúra CNN modelu\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = Conv1D(filters=100, kernel_size=2, padding='valid', activation='relu', strides=1)(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model_cnn = Model(inputs=inputs, outputs=output)\n",
    "model_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model_cnn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie modelu\n",
    "saved_model = \"model_cnn_home_sostop.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trénovanie modelu\n",
    "history = model_cnn.fit(train_padding, y_train, epochs=5, batch_size=32, validation_split=0.1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#načítanie modelu\n",
    "model_cnn=load_model('model_cnn_home_sostop.hdf5')\n",
    "\n",
    "#predikcia na testovacích dátach pomocou natrénovaného modelu,\n",
    "#vypísanie kontingenčnej tabuľky a metrík na vyhodnotenie ako úspešnosť, návrtanosť, F1 ...\n",
    "y_cnn = model_cnn.predict(test_padding)\n",
    "print('Roc auc score is {}'.format(roc_auc_score(y_test, y_cnn)))\n",
    "y_int = np.zeros_like(y_cnn)\n",
    "y_int[y_cnn > 0.5] = 1\n",
    "print('Accuracy is {}'.format(accuracy_score(y_test,y_int)))\n",
    "\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              | Precision | Recall | F1-score | Support |\n",
    "|:------------:|:---------:|:------:|:--------:|:-------:|\n",
    "|       0      |    0.94   |  0.98  |   0.96   |   6495  |\n",
    "|       1      |    0.95   |  0.87  |   0.91   |   2776  |\n",
    "|              |           |        |          |         |\n",
    "|   Accuracy   |           |        |   0.95   |   9271  |\n",
    "|   Macro avg  |    0.95   |  0.92  |   0.93   |   9271  |\n",
    "| Weighted avg |    0.95   |  0.95  |   0.95   |   9271  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy : 0.946068\n",
    "\n",
    "ROC : 0.977517"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Actual/Predicted | Fake news | True news |\n",
    "|------------------|-----------|-----------|\n",
    "| Fake news        |   TP-2402  |   FN-374  |\n",
    "| True news        |   FP-126  |  TN-6369  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_2 (Embedding)      (None, 1000, 100)         20194200  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 128)               117248    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 20,328,089\n",
      "Trainable params: 20,328,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#architektúra LSTM modelu\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = LSTM(128)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model_lstm = Model(inputs=inputs, outputs=output)\n",
    "model_lstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model_lstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie modelu\n",
    "saved_model = \"model_lstm_home_sostop.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trénovanie modelu\n",
    "history = model_lstm.fit(train_padding, y_train, epochs=5, batch_size=32, validation_split=0.1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#načítanie modelu\n",
    "model_lstm=load_model('model_lstm_home_sostop.hdf5')\n",
    "\n",
    "#predikcia na testovacích dátach pomocou natrénovaného modelu,\n",
    "#vypísanie kontingenčnej tabuľky a metrík na vyhodnotenie ako úspešnosť, návrtanosť, F1 ...\n",
    "y_cnn = model_lstm.predict(test_padding)\n",
    "print('Roc auc score is {}'.format(roc_auc_score(y_test, y_cnn)))\n",
    "y_int = np.zeros_like(y_cnn)\n",
    "y_int[y_cnn > 0.5] = 1\n",
    "print('Accuracy is {}'.format(accuracy_score(y_test,y_int)))\n",
    "\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              | Precision | Recall | F1-score | Support |\n",
    "|:------------:|:---------:|:------:|:--------:|:-------:|\n",
    "|       0      |    0.94   |  1.00  |   0.97   |   6495  |\n",
    "|       1      |    0.99   |  0.86  |   0.92   |   2776  |\n",
    "|              |           |        |          |         |\n",
    "|   Accuracy   |           |        |   0.96   |   9271  |\n",
    "|   Macro avg  |    0.97   |  0.93  |   0.94   |   9271  |\n",
    "| Weighted avg |    0.96   |  0.96  |   0.95   |   9271  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy : 0.955129\n",
    "\n",
    "ROC : 0.968030"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Actual/Predicted | Fake news | True news |\n",
    "|------------------|-----------|-----------|\n",
    "| Fake news        |   TP-2376  |   FN-400  |\n",
    "| True news        |   FP-16  |  TN-6479  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 1000, 100)         20194200  \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 1000, 100)         0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 1000, 128)         84480     \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 998, 32)           12320     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 20,293,177\n",
      "Trainable params: 20,293,177\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#architektúra Bi-LSTM + CNN modelu\n",
    "inputs = Input(shape=(max_length,))\n",
    "x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "x = SpatialDropout1D(0.2)(x)\n",
    "x = Bidirectional(LSTM(64, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "x = Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "x = GlobalMaxPooling1D()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.2)(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "model_bilstm = Model(inputs=inputs, outputs=output)\n",
    "model_bilstm.compile(loss='binary_crossentropy', optimizer='adam', metrics=['acc'])\n",
    "print(model_bilstm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#uloženie modelu\n",
    "saved_model = \"model_bilstm_home_sostop.hdf5\"\n",
    "checkpoint = ModelCheckpoint(saved_model, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trénovanie modelu\n",
    "history = model_bilstm.fit(train_padding, y_train, epochs=5, batch_size=32, validation_split=0.1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#načítanie modelu\n",
    "model_bilstm=load_model('model_bilstm_home_sostop.hdf5')\n",
    "\n",
    "#predikcia na testovacích dátach pomocou natrénovaného modelu,\n",
    "#vypísanie kontingenčnej tabuľky a metrík na vyhodnotenie ako úspešnosť, návrtanosť, F1 ...\n",
    "y_cnn = model_bilstm.predict(test_padding)\n",
    "print('Roc auc score is {}'.format(roc_auc_score(y_test, y_cnn)))\n",
    "y_int = np.zeros_like(y_cnn)\n",
    "y_int[y_cnn > 0.5] = 1\n",
    "print('Accuracy is {}'.format(accuracy_score(y_test,y_int)))\n",
    "\n",
    "print(classification_report(y_test, y_int, zero_division=0))\n",
    "print(confusion_matrix(y_test, y_int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|              | Precision | Recall | F1-score | Support |\n",
    "|:------------:|:---------:|:------:|:--------:|:-------:|\n",
    "|       0      |    0.95   |  0.99  |   0.97   |   6495  |\n",
    "|       1      |    0.98   |  0.89  |   0.93   |   2776  |\n",
    "|              |           |        |          |         |\n",
    "|   Accuracy   |           |        |   0.96   |   9271  |\n",
    "|   Macro avg  |    0.96   |  0.94  |   0.95   |   9271  |\n",
    "| Weighted avg |    0.96   |  0.96  |   0.96   |   9271  |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy : 0.959551\n",
    "\n",
    "ROC : 0.986082"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Actual/Predicted | Fake news | True news |\n",
    "|------------------|-----------|-----------|\n",
    "| Fake news        |   TP-2462  |   FN-314  |\n",
    "| True news        |   FP-61  |  TN-6434  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definovanie modelu Bi-LSTM + CNN pre optimalizáciu hyperparametrov pomocou Grid search\n",
    "def bilstm_model(dropout_rate=0.2, activation='relu',optimizer='adam'):\n",
    "    inputs = Input(shape=(max_length,))\n",
    "    x = Embedding(num_words, EMBEDDING_DIM, weights=[embedding_matrix])(inputs)\n",
    "    x = SpatialDropout1D(dropout_rate)(x)\n",
    "    x = Bidirectional(LSTM(64, return_sequences=True,dropout=0.1,recurrent_dropout=0.1))(x)\n",
    "    x = Conv1D(32, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(x)\n",
    "    x = GlobalMaxPooling1D()(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(dropout_rate)(x)\n",
    "    output = Dense(1, activation='sigmoid')(x)\n",
    "    model = Model(inputs=inputs, outputs=output)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KerasClassifier(build_fn=bilstm_model, epochs=5)\n",
    "\n",
    "import sys\n",
    "class Tee(object):\n",
    "    def __init__(self, *files):\n",
    "        self.files = files\n",
    "    def write(self, obj):\n",
    "        for f in self.files:\n",
    "            f.write(obj)\n",
    "            f.flush() \n",
    "    def flush(self) :\n",
    "        for f in self.files:\n",
    "            f.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#definovanie parametrov pre Grid search\n",
    "dropout_rate = [0.1, 0.2]\n",
    "batch_size = [16, 32]\n",
    "optimizer = ['SGD','Adam']\n",
    "f = open('out_Homenews.txt', 'w')\n",
    "original = sys.stdout\n",
    "sys.stdout = Tee(sys.stdout, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = dict(batch_size=batch_size, dropout_rate=dropout_rate, optimizer=optimizer)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trénovanie optimalizácie Grid search\n",
    "grid_result = grid.fit(train_padding, y_train, verbose=2)\n",
    "\n",
    "#výsledky po Grid search\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means_acc = grid_result.cv_results_['mean_test_score']\n",
    "stds_acc = grid_result.cv_results_['std_test_score']\n",
    "params_acc = grid_result.cv_results_['params']\n",
    "\n",
    "for  means_acc, stds_acc, params_acc in zip(means_acc, stds_acc, params_acc):\n",
    "    print(\"%f (%f) with: %r\" % (means_acc, stds_acc, params_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.949963 using {'batch_size': 32, 'dropout_rate': 0.2, 'optimizer': 'Adam'}<br/>\n",
    "0.934980 (0.001757) with: {'batch_size': 16, 'dropout_rate': 0.1, 'optimizer': 'SGD'}<br/>\n",
    "0.944969 (0.003977) with: {'batch_size': 16, 'dropout_rate': 0.1, 'optimizer': 'Adam'}<br/>\n",
    "0.934980 (0.003052) with: {'batch_size': 16, 'dropout_rate': 0.2, 'optimizer': 'SGD'}<br/>\n",
    "0.947096 (0.001850) with: {'batch_size': 16, 'dropout_rate': 0.2, 'optimizer': 'Adam'}<br/>\n",
    "0.949963 (0.000832) with: {'batch_size': 32, 'dropout_rate': 0.2, 'optimizer': 'Adam'}<br/>\n",
    "0.896226 (0.000370) with: {'batch_size': 32, 'dropout_rate': 0.1, 'optimizer': 'SGD'}<br/>\n",
    "0.946911 (0.002035) with: {'batch_size': 32, 'dropout_rate': 0.1, 'optimizer': 'Adam'}<br/>\n",
    "0.922124 (0.000555) with: {'batch_size': 32, 'dropout_rate': 0.2, 'optimizer': 'SGD'}<br/>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
